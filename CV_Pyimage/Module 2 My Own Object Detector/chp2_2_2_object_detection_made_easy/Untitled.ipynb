{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python David_2_2_2_test_detector.py --detector \"Airplane/output/airplane.svm\" --testing testing\n",
    "\n",
    "# 1. Preprocessing (!!)  import dlib / from imutils import paths\n",
    "\n",
    "    # import the necessary packages\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "    # 1.1 Set testing path\n",
    "    # construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--detector\", required=True, help=\"Path to trained object detector\")\n",
    "ap.add_argument(\"-t\", \"--testing\", required=True, help=\"Path to directory of testing images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-t', '--testing'], dest='testing', nargs=None, const=None, default=None, type=None, choices=None, help='Path to directory of testing images', metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "#sys.argv[1:] = '-d output/stop_sign_detector.svm -t stop_sign_testing'.split()\n",
    "#sys.argv[1:] = '-d Airplane\\\\output\\\\airplane.svm -t Airplane\\\\testing'.split()\n",
    "sys.argv[1:] = '-d Airplane1\\\\output\\\\airplane1.svm -t Airplane1\\\\testing'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open Airplane1\\output\\airplane1.svm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-61a7b4657732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# 2. load the detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimple_object_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"detector\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# loop over the testing images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open Airplane1\\output\\airplane1.svm"
     ]
    }
   ],
   "source": [
    "# python David_2_2_2_test_detector.py --detector output/stop_sign_detector.svm --testing stop_sign_testing\n",
    "# python David_2_2_2_test_detector.py --detector \"Airplane/output/airplane.svm\" --testing testing\n",
    "\n",
    "# 1. Preprocessing \n",
    "#(!!)  import dlib / from imutils import paths\n",
    "\n",
    "    # import the necessary packages\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "    # 1.1 Set testing path\n",
    "    # construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--detector\", required=True, help=\"Path to trained object detector\")\n",
    "ap.add_argument(\"-t\", \"--testing\", required=True, help=\"Path to directory of testing images\")\n",
    "\n",
    "import sys \n",
    "#sys.argv[1:] = '-d output/stop_sign_detector.svm -t stop_sign_testing'.split()\n",
    "#sys.argv[1:] = '-d Airplane\\\\output\\\\airplane.svm -t Airplane\\\\testing'.split()\n",
    "sys.argv[1:] = '-d Airplane1\\\\output\\\\airplane1.svm -t Airplane1\\\\testing'.split()\n",
    "\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# 2. load the detector\n",
    "detector = dlib.simple_object_detector(args[\"detector\"])\n",
    "\n",
    "# loop over the testing images\n",
    "for testingPath in paths.list_images(args[\"testing\"]):\n",
    "\t# load the image and make predictions\n",
    "\timage = cv2.imread(testingPath)\n",
    "\tboxes = detector(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\t# loop over the bounding boxes and draw them\n",
    "\tfor b in boxes:\n",
    "\t\t(x, y, w, h) = (b.left(), b.top(), b.right(), b.bottom())\n",
    "\t\tcv2.rectangle(image, (x, y), (w, h), (0, 255, 0), 2)\n",
    "\n",
    "\t# show the image\n",
    "\tcv2.imshow(\"Image\", image)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] gathering images and bounding boxes...\n"
     ]
    }
   ],
   "source": [
    "# python David_2_2_2_train_detector.py --class \"../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2/stop_sign_images --annotations ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2/stop_sign_annotations --output output/stop_sign_detector.svm\n",
    "\n",
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from imutils import paths\n",
    "from scipy.io import loadmat\n",
    "from skimage import io\n",
    "import argparse\n",
    "import dlib\n",
    "import sys\n",
    "\n",
    "# handle Python 3 compatibility\n",
    "if sys.version_info > (3,):\n",
    "\tlong = int\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-c\", \"--class\", required=True,\n",
    "\thelp=\"Path to the CALTECH-101 class images\")\n",
    "ap.add_argument(\"-a\", \"--annotations\", required=True,\n",
    "\thelp=\"Path to the CALTECH-101 class annotations\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "\thelp=\"Path to the output detector\")\n",
    "\n",
    "\n",
    "# import sys \n",
    "# sys.argv[1:] = '-c stop_sign_images -a stop_sign_annotations -o output/stop_sign_detector.svm'.split()\n",
    "# sys.argv[1:] = '-c Airplane/image -a Airplane/annotations -o Airplane/output/airplane.svm'.split()\n",
    "sys.argv[1:] = '-c ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_images -a ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations -o ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/output/2020StopSignTest.svm'.split()\n",
    "\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "# grab the default training options for our HOG + Linear SVM detector initialize the\n",
    "# list of images and bounding boxes used to train the classifier\n",
    "print(\"[INFO] gathering images and bounding boxes...\")\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "images = []\n",
    "boxes = []\n",
    "\n",
    "for imagePath in paths.list_images(args[\"class\"]):\n",
    "    # extract the image ID from the image path and load the annotations file\n",
    "    imageID = imagePath[imagePath.rfind(\"/\") + 1:].split(\"_\")[1]\n",
    "    #print(imageID)\n",
    "    id1= imagePath.find(\"\\\\\")\n",
    "    #print(id1)\n",
    "    id2= imagePath[id1+1:]\n",
    "    #print(id2)\n",
    "    imageID = id2.replace(\".jpg\", \"\")\n",
    "    #print(imageID)\n",
    "    str = imageID[6:]\n",
    "    #print(str)\n",
    "    #dir= \"./Airplane1/annotations/\"\n",
    "    dir= \"./stop_sign_annotations/\"\n",
    "    #print(dir)\n",
    "    p = \"{}annotation_{}.mat\".format(dir, str)\n",
    "    #print(p)\n",
    "    annotations = loadmat(p)[\"box_coord\"]\n",
    "    #print(annotations)\n",
    "    bb = [dlib.rectangle(left=long(x), top=long(y), right=long(w), bottom=long(h)) \n",
    "        for (y, h, x, w) in annotations]\n",
    "    #print(bb)\n",
    "    boxes.append(bb)    \n",
    "    #print(boxes)\n",
    "    #print(len(boxes))\n",
    "    # add the image to the list of images\n",
    "    images.append(io.imread(imagePath))\n",
    "    #print(images)\n",
    "    \n",
    "# train the object detector\n",
    "print(\"[INFO] training detector...\")\n",
    "detector = dlib.train_simple_object_detector(images, boxes, options)\n",
    "\n",
    "# dump the classifier to file\n",
    "print(\"[INFO] dumping classifier to file...\")\n",
    "detector.save(args[\"output\"])\n",
    "\n",
    "# visualize the results of the detector\n",
    "win = dlib.image_window()\n",
    "win.set_image(detector)\n",
    "dlib.hit_enter_to_continue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] gathering images and bounding boxes...\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0001.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0002.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0003.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0004.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0005.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0006.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0007.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0008.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0009.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0010.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0011.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0012.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0013.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0014.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0015.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0016.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0017.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0018.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0019.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0020.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0021.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0022.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0023.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0024.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0025.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0026.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0027.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0028.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0029.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0030.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0031.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0032.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0033.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0034.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0035.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0036.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0037.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0038.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0039.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0040.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0041.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0042.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0043.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0044.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0045.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0046.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0047.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0048.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0049.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0050.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0051.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0052.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0053.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0054.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0055.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0056.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0057.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0058.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0059.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0060.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0061.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0062.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0063.mat\n",
      "../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_0064.mat\n"
     ]
    }
   ],
   "source": [
    "# python David_2_2_2_train_detector.py --class \"../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2/stop_sign_images --annotations ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2/stop_sign_annotations --output output/stop_sign_detector.svm\n",
    "\n",
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from imutils import paths\n",
    "from scipy.io import loadmat\n",
    "from skimage import io\n",
    "import argparse\n",
    "import dlib\n",
    "import sys\n",
    "\n",
    "# handle Python 3 compatibility\n",
    "if sys.version_info > (3,):\n",
    "\tlong = int\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-c\", \"--class\", required=True,\n",
    "\thelp=\"Path to the CALTECH-101 class images\")\n",
    "ap.add_argument(\"-a\", \"--annotations\", required=True,\n",
    "\thelp=\"Path to the CALTECH-101 class annotations\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "\thelp=\"Path to the output detector\")\n",
    "\n",
    "\n",
    "# import sys \n",
    "# sys.argv[1:] = '-c stop_sign_images -a stop_sign_annotations -o output/stop_sign_detector.svm'.split()\n",
    "# sys.argv[1:] = '-c Airplane/image -a Airplane/annotations -o Airplane/output/airplane.svm'.split()\n",
    "# sys.argv[1:] = '-c ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_images -a ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations -o ../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/output/2020StopSignTest.svm'.split()\n",
    "\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "# grab the default training options for our HOG + Linear SVM detector initialize the\n",
    "# list of images and bounding boxes used to train the classifier\n",
    "print(\"[INFO] gathering images and bounding boxes...\")\n",
    "options = dlib.simple_object_detector_training_options()\n",
    "images = []\n",
    "boxes = []\n",
    "\n",
    "for imagePath in paths.list_images(args[\"class\"]):\n",
    "    # extract the image ID from the image path and load the annotations file\n",
    "    imageID = imagePath[imagePath.rfind(\"/\") + 1:].split(\"_\")[1]\n",
    "    #print(imageID)\n",
    "    id1= imagePath.find(\"\\\\\")\n",
    "    #print(id1)\n",
    "    id2= imagePath[id1+1:]\n",
    "    #print(id2)\n",
    "    imageID = id2.replace(\".jpg\", \"\")\n",
    "    #print(imageID)\n",
    "    str = imageID[6:]\n",
    "    #print(str)\n",
    "    #dir= \"./Airplane1/annotations/\"\n",
    "    dir= \"./stop_sign_annotations/\"\n",
    "    #p = \"{}annotation_{}.mat\".format(dir, str)\n",
    "    p = \"{}/annotation_{}.mat\".format(args[\"annotations\"], imageID[6:])\n",
    "\n",
    "    print(p)\n",
    "    annotations = loadmat(p)[\"box_coord\"]\n",
    "    #print(annotations)\n",
    "    bb = [dlib.rectangle(left=long(x), top=long(y), right=long(w), bottom=long(h)) \n",
    "        for (y, h, x, w) in annotations]\n",
    "    #print(bb)\n",
    "    boxes.append(bb)    \n",
    "    #print(boxes)\n",
    "    #print(len(boxes))\n",
    "    # add the image to the list of images\n",
    "    images.append(io.imread(imagePath))\n",
    "    #print(images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_sign.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_sign.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-774eae25b265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mimageID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"{}/annotation_{}.mat\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"annotations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimageID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"box_coord\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# loop over the annotations and add each annotation to the list of bounding boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \"\"\"\n\u001b[0;32m    215\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow2\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../CV_PyImageSearch/Dataset/Chapter_Specific/chp2_2_stop_sign/stop_sign_annotations/annotation_sign.mat'"
     ]
    }
   ],
   "source": [
    "for imagePath in paths.list_images(args[\"class\"]):\n",
    "\t# extract the image ID from the image path and load the annotations file\n",
    "\timageID = imagePath[imagePath.rfind(\"/\") + 1:].split(\"_\")[1]\n",
    "\timageID = imageID.replace(\".jpg\", \"\")\n",
    "\tp = \"{}/annotation_{}.mat\".format(args[\"annotations\"], imageID)\n",
    "\tannotations = loadmat(p)[\"box_coord\"]\n",
    "\n",
    "\t# loop over the annotations and add each annotation to the list of bounding boxes\n",
    "\tbb = [dlib.rectangle(left=long(x), top=long(y), right=long(w), bottom=long(h))\n",
    "\t\t for (y, h, x, w) in annotations]\n",
    "\tboxes.append(bb)\n",
    "\n",
    "\t# add the image to the list of images\n",
    "\timages.append(io.imread(imagePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
